{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "import io\n",
    "from docx2pdf import convert\n",
    "from pathlib import Path\n",
    "from nltk.corpus import stopwords\n",
    "from stop_words import get_stop_words\n",
    "import os\n",
    "import pythoncom\n",
    "import win32com.client\n",
    "import base64\n",
    "class ResumeAnalyzer:\n",
    "    def __init__(self, resume_file):\n",
    "        self.resume_file = resume_file\n",
    "        \n",
    "    def load_resume(self):\n",
    "        # Load the resume file into memory\n",
    "        with open(self.resume_file, 'r') as f:\n",
    "            resume_text = f.read()\n",
    "        return resume_text\n",
    "    \n",
    "    def process_text(self):\n",
    "        pythoncom.CoInitialize()\n",
    "        analyzer = self.resume_file\n",
    "\n",
    "    # Check if the file is a PDF or DOCX file\n",
    "        if analyzer.endswith('.pdf'):\n",
    "            pdf_file = open(analyzer, 'rb')\n",
    "        elif analyzer.endswith('.docx'):\n",
    "        # Convert the DOCX file to a PDF file         \n",
    "            \n",
    "            \n",
    "            \n",
    "            word = win32com.client.Dispatch('Word.Application')\n",
    "            doc = word.Documents.Add(str(analyzer))\n",
    "             # Save the DOCX file as a PDF file\n",
    "            pdf_file_path = str(analyzer).replace('.docx', '.pdf')\n",
    "            doc.SaveAs(pdf_file_path, FileFormat=17)\n",
    "        \n",
    "            # Close the DOCX file\n",
    "            doc.Close()\n",
    "            word.Quit()\n",
    "        \n",
    "            # Open the PDF file\n",
    "            pdf_file = open(pdf_file_path.replace('.docx', '.pdf'), 'rb')\n",
    "                \n",
    "            \n",
    "\n",
    "        \n",
    "          \n",
    "        else:\n",
    "            print(\"ERROR: only format of docx or PDF\")\n",
    "            return\n",
    "\n",
    "    # Extract text from the PDF file\n",
    "        resMgr = PDFResourceManager()\n",
    "        retData = io.StringIO()\n",
    "        TxtConverter = TextConverter(resMgr, retData, laparams=LAParams())\n",
    "        interpreter = PDFPageInterpreter(resMgr, TxtConverter)\n",
    "\n",
    "        for page in PDFPage.get_pages(pdf_file):\n",
    "            interpreter.process_page(page)\n",
    "\n",
    "        txt = retData.getvalue()\n",
    "\n",
    "    # Save the extracted text to a TXT file\n",
    "        txt_file = open(analyzer.replace('.pdf', '.txt'), 'w')\n",
    "        txt_file.write(txt)\n",
    "\n",
    "        return txt\n",
    "\n",
    "    \n",
    "    \n",
    "    def extract_words(self, resume_text):\n",
    "        # Use regular expressions to extract only words from the resume text\n",
    "        words = re.findall(r'\\b[a-zA-Z]+\\b', resume_text)\n",
    "        return words\n",
    "    \n",
    "    def count_data_science_words(self, words):\n",
    "        # Use a set to store the words related to data science\n",
    "        data_science_words = {'Python', 'R', 'SQL', 'Machine Learning',\"AI\",\"Data Science\", 'Data Mining', 'Data Analysis',\"DATA\",\"spark\",\"MYSQL\",\"ml\",\"algorithm\",\"neural network\",\"deep learning\"}\n",
    "        data_science_words ={data_buzz.lower() for data_buzz in data_science_words}\n",
    "        # Count the number of words in the resume that are related to data science\n",
    "        count = 0\n",
    "        for word in words:\n",
    "            if word in data_science_words:\n",
    "                count += 1\n",
    "        return count\n",
    "    \n",
    "    def process_word(self, words):        \n",
    "        words = [word.lower() for word in words]\n",
    "        words = [word for word in words if word not in stopwords.words('english')]\n",
    "        words = [word for word in words if word not in get_stop_words('en')]\n",
    "        return words\n",
    "    \n",
    "    def count_data_science_words_occurrences(self, words):\n",
    "    # Use a set to store the words related to data science\n",
    "        data_science_words = {'Python', 'R', 'SQL', 'Machine Learning',\"AI\",\"Data Science\", 'Data Mining', 'Data Analysis',\"DATA\",\"spark\",\"MYSQL\",\"ml\",\"algorithm\",\"neural network\",\"deep learning\"}\n",
    "        data_science_words = {word.lower() for word in data_science_words}\n",
    "    \n",
    "    # Create a dictionary to store the number of occurrences of each data science-related word\n",
    "        word_counts = {}\n",
    "        for word in words:\n",
    "            if word in data_science_words:\n",
    "                if word not in word_counts:\n",
    "                    word_counts[word] = 1\n",
    "                else:\n",
    "                    word_counts[word] += 1\n",
    "        word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        return word_counts\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'ResumeAnalyzer(file={self.resume_file})'\n",
    "    \n",
    "    def analyze(self):\n",
    "    # Load the resume file\n",
    "        resume_text = self.load_resume()\n",
    "        \n",
    "        # Process the text to extract the individual words\n",
    "        words = self.process_text()\n",
    "        \n",
    "        # Count the number of data science-related words\n",
    "        data_science_word_count = self.count_data_science_words(words)\n",
    "        \n",
    "        # Count the number of occurrences of each data science-related word\n",
    "        data_science_word_occurrences = self.count_data_science_words_occurrences(words)\n",
    "        \n",
    "        # Return a dictionary containing the analysis results\n",
    "        return {\n",
    "            'data_science_word_count': data_science_word_count,\n",
    "            'data_science_word_occurrences': data_science_word_occurrences,\n",
    "        }\n",
    "\n",
    "    \n",
    "    \n",
    "    def plot_word_cloud(self, words):\n",
    "        # Generate a word cloud from the list of words\n",
    "        wordcloud = WordCloud(width=800, height=400).generate(' '.join(words))\n",
    "        \n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "def apply_word_cloud(path):\n",
    "    analyzer = ResumeAnalyzer(path)\n",
    "    txt = analyzer.process_text()\n",
    "    try:\n",
    "        words = analyzer.extract_words(txt)\n",
    "        words = analyzer.process_word(words)\n",
    "    # Count the number of data science-related words in the resume\n",
    "        count = analyzer.count_data_science_words(words)\n",
    "        word_counts = analyzer.count_data_science_words_occurrences(words)\n",
    "        print(f'Number of data science-related words: {count}')\n",
    "        print(f\"this the word_counts {word_counts}\")\n",
    "        if 0.06 < count/len(words) and len(words)>50:\n",
    "            name_candidate = Path(path).name.replace(\".pdf\",\"\").replace(\".docx\",\"\").replace(\".txt\",\"\").replace(\" CV\",\"\").replace(\" cv\",\"\").replace(\"_cv\",\"\").replace(\"_CV\",\"\").replace(\"_\",\" \")\n",
    "            print(f\"This hot finding, call now to {name_candidate} !!\")\n",
    "        \n",
    "        else:\n",
    "            print(\"Try more buzz words!!!\")\n",
    "    \n",
    "    # Generate and display a word cloud from the list of words in the resume\n",
    "        \n",
    "        analyzer.plot_word_cloud(words)\n",
    "    except:\n",
    "        name_candidate = Path(path).name\n",
    "        print(f\"ERROR: please try to cnovert file: {name_candidate} to docx or PDF only format allow\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_word_cloud2(path):\n",
    "    analyzer = ResumeAnalyzer(path)\n",
    "    txt = analyzer.process_text()\n",
    "    try:\n",
    "        words = analyzer.extract_words(txt)\n",
    "        words = analyzer.process_word(words)\n",
    "    # Count the number of data science-related words in the resume\n",
    "        count = analyzer.count_data_science_words(words)\n",
    "        word_counts = analyzer.count_data_science_words_occurrences(words)\n",
    "        #print(f'Number of data science-related words: {count}')\n",
    "        #print(f\"this the word_counts {word_counts}\")\n",
    "        if 0.06 < count/len(words) and len(words)>50:\n",
    "            name_candidate = Path(path).name.replace(\".pdf\",\"\").replace(\".docx\",\"\").replace(\".txt\",\"\").replace(\" CV\",\"\").replace(\" cv\",\"\").replace(\"_cv\",\"\").replace(\"_CV\",\"\").replace(\"_\",\" \")\n",
    "            #print(f\"This hot finding, call now to {name_candidate} !!\")\n",
    "            \n",
    "        else:\n",
    "            name_candidate =\"Try more buzz words and then your name will be apper!!!\"\n",
    "    \n",
    "    # Generate and display a word cloud from the list of words in the resume\n",
    "        \n",
    "        return word_counts,name_candidate\n",
    "    except:\n",
    "        name_candidate = Path(path).name\n",
    "        print(f\"ERROR: please try to cnovert file: {name_candidate} to docx or PDF only format allow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_word_cloud3(path):\n",
    "    analyzer = ResumeAnalyzer(path)\n",
    "    txt = analyzer.process_text()\n",
    "    try:\n",
    "        words = analyzer.extract_words(txt)\n",
    "        words = analyzer.process_word(words)\n",
    "    # Count the number of data science-related words in the resume\n",
    "        count = analyzer.count_data_science_words(words)\n",
    "        word_counts = analyzer.count_data_science_words_occurrences(words)\n",
    "        #print(f'Number of data science-related words: {count}')\n",
    "        #print(f\"this the word_counts {word_counts}\")\n",
    "        if 0.06 < count/len(words) and len(words)>50:\n",
    "            name_candidate = Path(path).name.replace(\".pdf\",\"\").replace(\".docx\",\"\").replace(\".txt\",\"\").replace(\" CV\",\"\").replace(\" cv\",\"\").replace(\"_cv\",\"\").replace(\"_CV\",\"\").replace(\"_\",\" \")\n",
    "            #print(f\"This hot finding, call now to {name_candidate} !!\")\n",
    "        \n",
    "        else:\n",
    "            name_candidate =\"Try more buzz words!!!\"\n",
    "            print(\"Try more buzz words!!!\")\n",
    "        if not words:\n",
    "            print('Error: words list is empty or None')\n",
    "            return\n",
    "    # Generate and display a word cloud from the list of words in the resume\n",
    "        \n",
    "        #plot_word_cloud(words)\n",
    "        \n",
    "        wordcloud = WordCloud(width=800, height=400).generate(' '.join(words))\n",
    "        \n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()  \n",
    "\n",
    "        # Save the word cloud to a file\n",
    "        template_dir = os.path.dirname(path)\n",
    "        image_file_path = os.path.join(template_dir, \"wordcloud.png\")\n",
    "        # Display the word cloud\n",
    "        try:\n",
    "    # Save the word cloud to a file\n",
    "            wordcloud.to_file(image_file_path)\n",
    "        except Exception as e:\n",
    "    # Print an error message if the file could not be saved\n",
    "            print(f'Error: Could not save word cloud to {image_file_path}: {e}')\n",
    "    except:\n",
    "        name_candidate = Path(path).name\n",
    "        print(f\"ERROR: please try to cnovert file: {name_candidate} to docx or PDF only format allow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [ r'C:\\Users\\יותם בראון\\Desktop\\Yotam Braun CV.pdf' ,r'C:\\Users\\יותם בראון\\Desktop\\Shachar_CV.pdf',r'C:\\Users\\יותם בראון\\Desktop\\simple_test.txt']\n",
    "\n",
    "for path in paths:\n",
    "    apply_word_cloud(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [ r'C:\\Users\\יותם בראון\\Desktop\\Yotam Braun CV.pdf' ,r'C:\\Users\\יותם בראון\\Desktop\\Shachar_CV.pdf',r'C:\\Users\\יותם בראון\\Desktop\\simple_test.txt']\n",
    "\n",
    "for path in paths:\n",
    "    apply_word_cloud(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, render_template,session\n",
    "\n",
    "app = Flask(__name__, template_folder=r'C:\\Users\\יותם בראון\\Desktop\\templates')\n",
    "IMG_FOLDER = os.path.join('static', 'IMG')\n",
    "UPLOAD_FOLDER = os.path.join('staticFiles', 'uploads')\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "@app.route('/')\n",
    "def index():\n",
    "    \n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/analyze', methods=[\"GET\",'POST'])\n",
    "def analyze():\n",
    "    # Get the uploaded file from the request data\n",
    "    file = request.files['resume_file']\n",
    "    file_path1 = os.path.join(r'C:\\Users\\יותם בראון\\Desktop\\templates',file.filename)\n",
    "    # Save the file to a temporary location on the server\n",
    "    file_path = os.path.join(r'C:\\Users\\יותם בראון\\Desktop\\templates\\tmp', file.filename)\n",
    "    file.save(file_path)\n",
    "    print(file_path)\n",
    "    # Create a ResumeAnalyzer object and analyze the resume\n",
    "    #analyzer = ResumeAnalyzer(file_path)\n",
    "    #analysis = analyzer.analyze()\n",
    "    analysis=apply_word_cloud2(file_path)[0]\n",
    "    print(analysis)\n",
    "    analysis1=apply_word_cloud2(file_path)[1]\n",
    "    print(analysis1)\n",
    "    analysis_2=apply_word_cloud3(file_path1)\n",
    " \n",
    "    # Render the results page and pass the analysis results as data\n",
    "    response = render_template('results.html', analysis=analysis,analysis1=analysis1)\n",
    "\n",
    "    return response\n",
    "\n",
    "@app.route('/show_image', methods=[\"GET\", \"POST\"])\n",
    "def displayImage():\n",
    "    img_file_path = session.get(\"uploaded_img_file_path\", None)\n",
    "    # Save uploaded image file to UPLOAD_FOLDER if a file was uploaded\n",
    "    if request.method == 'POST':\n",
    "        uploaded_img = request.files['uploaded_img']\n",
    "        uploaded_img.save(os.path.join(app.config['UPLOAD_FOLDER'], 'Wordcloud.png'))\n",
    "        session['uploaded_img_file_path'] = os.path.join(app.config['UPLOAD_FOLDER'], 'Wordcloud.png')\n",
    "    print(img_file_path)\n",
    "    if not img_file_path:\n",
    "        img_file_path = r'C:\\Users\\יותם בראון\\Desktop\\templates\\Wordcloud.png'\n",
    "    # Render show_image.html template and pass user_image variable\n",
    "    response = render_template('show_image.html', user_image=img_file_path)\n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
